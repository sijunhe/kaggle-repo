{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import re\n",
    "from patsy import dmatrices\n",
    "%matplotlib inline  \n",
    "train = pd.read_csv('train.csv', header = 0)\n",
    "test = pd.read_csv('test.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "In last post, we have done some exploratory analysis of the data and also built two simple models, which gave us decent prediction accuracy. In this post, our question is, Can we do better? \n",
    "We left off last time with Logistic Regression. And hopefully we just need to feed more predicators to the model for a better accuracy. However, before we can do that, we need to clean our data. We see that there are NAs in the Age, Fare, Cabin, and Embarked variables, so we will have to impute these values. For the Cabin variable, there are way too many NAs so imputing all those values would bring it an significant amount of noise. And the Cabin variable itself is hard to interpret anyways. So we will just impute the Age, Fare and Embarked variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # drop predicators that we are not going to use\n",
    "    df.drop(['Ticket','Cabin'],inplace=True,axis=1)\n",
    "    \n",
    "    # encode the sex class to 0, 1\n",
    "    df['Sex'] = df.Sex.map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "    # simply fill the missing Embarked value with \"S\" since there are only 2 NAs\n",
    "    df['Embarked'] = df.Embarked.fillna('S')\n",
    "    \n",
    "    # there is a 0 value in Fare column, which is unreasonable. Will have to replace it with NA first.\n",
    "    df.Fare = df.Fare.map(lambda x: np.nan if x==0 else x)\n",
    "    # build a pivot table to impute NAs with averaged Fare for all Pclass\n",
    "    fare_pivot_table = df.pivot_table(\"Fare\", index='Pclass', aggfunc='mean', dropna=True)\n",
    "    # use pivot table to impute missing fare values\n",
    "    df['Fare'] = df[['Fare', 'Pclass']].apply(lambda x: fare_pivot_table[x['Pclass']] if pd.isnull(x['Fare']) else x['Fare'], axis = 1)\n",
    "    \n",
    "    #build a pivot table to impute NAs with median Age according to Pclass and Sex\n",
    "    age_pivot_table = df.pivot_table('Age', index=['Pclass','Sex'], aggfunc='median',dropna=True)\n",
    "    df['Age'] = df[['Sex', 'Pclass', 'Age']].apply(lambda x: age_pivot_table[x.Pclass, x.Sex] if pd.isnull(x.Age) else x.Age, axis = 1)\n",
    "    \n",
    "    # define a age group categorical variable\n",
    "    df['AgeGroup'] = 'adult'\n",
    "    df.loc[ (df['Age']<=10) ,'AgeGroup'] = 'child'\n",
    "    df.loc[ (df['Age']>=60) ,'AgeGroup'] = 'senior'\n",
    "    \n",
    "    # define a fare group categorical variable\n",
    "    df['FareGroup'] = 'low'\n",
    "    df.loc[ (df['Fare']<=20) & (df['Fare']>10) ,'FareGroup'] = 'mid'\n",
    "    df.loc[ (df['Fare']<=30) & (df['Fare']>20) ,'FareGroup'] = 'mid-high'\n",
    "    df.loc[ (df['Fare']>30) ,'FareGroup'] = 'high'\n",
    "    \n",
    "    # Here we are adding interaction terms between predicators. I have included a few reasonable interaction terms in my mind \n",
    "    df['Family_Size']=train['SibSp']+train['Parch']+1\n",
    "    \n",
    "    # Generating the Title predicator\n",
    "    df['Title'] = df['Name'].apply(lambda x: getTitle(x))\n",
    "    df['Title'] = df.apply(getAndReplaceTitle, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def getTitle(name):\n",
    "    # use regex to match the titles in passenger names\n",
    "    # titles are the characters preceded by a comma and a space (\", \") and succeeded by a period (\".\") in a passenger's name.\n",
    "    # Here we use the positive lookbehind assertion to find the preceding (\", \") and the positive lookahead assertion to match the succeeding (\".\").\n",
    "    m = re.search('(?<=,\\s)[a-zA-z\\s]+(?=\\.)', name)\n",
    "    if m is None: \n",
    "        return np.nan\n",
    "    else:\n",
    "        return m.group(0)\n",
    "    \n",
    "def getAndReplaceTitle(df):\n",
    "    # combine similar titles\n",
    "    # the majority of the titles are pretty rare, which doesn't give much information about the passenger.\n",
    "    title = df['Title']\n",
    "    if title in ['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col','Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme','Mrs','Lady','Dona']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms','Miss']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "            if df['Sex']=='Male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "    else:\n",
    "        return title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did we impute the missing values, we also added in lots of additional predicators that could be correlated to the survival rate, since the correlation between survival rate and predicators might not be fully captured by the variables we had. Note that introducing new predicators, especaiily new categorical predicators, would increases the dimensionality of the data, which could potentially impact our prediction accuracy due to curse of dimensionality. Therefore we will use feature selection technique in our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:16: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n"
     ]
    }
   ],
   "source": [
    "train = clean_data(train)\n",
    "test = clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define a function in order to simplify future predictions and output\n",
    "def predictAndOutput(estimator, output_filename):\n",
    "        estimator.fit(train_data.values, train_response.values.ravel())\n",
    "        output = estimator.predict(test_data).astype(int)\n",
    "        submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"],\"Survived\": output})\n",
    "        submission.to_csv(output_filename, index=False)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "formula = 'Survived ~ C(Pclass) + Sex  + Age + SibSp + Parch + Family_Size + Fare + C(Embarked)+ C(Title) + C(AgeGroup)'\n",
    "train_response,train_data = dmatrices(formula, data=train, return_type=\"dataframe\")\n",
    "test['Survived'] = 1 #insert a dummy survived variable in order to create dmatrices\n",
    "test_response,test_data = dmatrices(formula, data=test, return_type=\"dataframe\")\n",
    "\n",
    "LRModel = LogisticRegression()\n",
    "# Exhaustive search over all parameter combinations for the estimator that produce the best CV error\n",
    "param_grid = {'penalty':['l1','l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "GridSearch = GridSearchCV(LRModel, param_grid, cv = 10)\n",
    "GridSearch.fit(train_data.values, train_response.values.ravel())\n",
    "bestLRclf = GridSearch.best_estimator_\n",
    "LRprediction = predictAndOutput(bestLRclf, \"LROutput.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got **0.77990** this times, which is an great improvement over the 2 simple models we had in last post. Hooray, moving up the ladder! Let's take a look at the classifier that gave us the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C(Pclass)[T.2] -0.905477959537\n",
      "C(Pclass)[T.3] -1.97896459743\n",
      "C(Embarked)[T.Q] 0.0\n",
      "C(Embarked)[T.S] -0.299162084187\n",
      "C(Title)[T.Miss] -0.573336914082\n",
      "C(Title)[T.Mr] -2.58797777339\n",
      "C(Title)[T.Mrs] 0.0\n",
      "C(AgeGroup)[T.child] 0.284813224479\n",
      "C(AgeGroup)[T.senior] 0.0\n",
      "Sex -0.78528900026\n",
      "Age -0.025393089303\n",
      "SibSp -0.49647079287\n",
      "Parch -0.266397881617\n",
      "Family_Size 0.0\n",
      "Fare 0.00330362443408\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(train_data.columns.values)):\n",
    "    print train_data.columns.values[i] , bestLRclf.coef_[0][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell from the coefficients of the predicators that some of the coefficients has been regularized to 0, which means that the predicator was not selected by the model. For the coefficients we can also observe the effect of the predicators. For example, passenger of Pclass 2 or 3would have a lower survival rate compared with passenger of Pclass 1 due to the negative coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move on to the more complicated Ensemble models, which usually offer the best out-of-box prediction accuracy. [Random Forest](https://en.wikipedia.org/wiki/Random_forest) is one of the most commonly-used Ensemble method that is operated by constructing a random multitude of decision trees at training time and outputting the class that is the mode of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFModel = RandomForestClassifier(random_state=1, n_estimators=200)\n",
    "param_grid = {'max_features':['sqrt',2, 5, 10, 15], 'min_samples_split':[4, 8, 10], 'min_samples_leaf':[2, 4, 6]}\n",
    "GridSearch = GridSearchCV(RFModel, param_grid, cv = 10)\n",
    "GridSearch.fit(train_data.values, train_response.values.ravel())\n",
    "bestRFclf = GridSearch.best_estimator_\n",
    "RFprediction = predictAndOutput(bestRFclf, \"RFOutput.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important parameters that we can tune for Random Forest is max_features, which is the number of features to consider when looking for the best split. Decreasing the max_features could improve randomness and reduce variance, while increasing the max_features would move the random forest more towards bagging. Min_samples_split and Min_samples_leaf are two stopping criteria of Random Forest that could contribute to overfitting. The GridSearchCV here is an exhaustive search over all parameter combinations for the estimator that produce the best 10-fold CV error.\n",
    "The Random Forest Method achieved an accuracy of **0.77990** again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAEKCAYAAABe7S+DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIyIi2iRBNiIiok0SZCMiItrk/wG3bvgi/dfGMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b178990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(bestRFclf.feature_importances_)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(len(train_data.columns.values)), bestRFclf.feature_importances_[indices], color=\"r\")\n",
    "plt.yticks(range(len(train_data.columns.values)), train_data.columns.values[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot illustrates the feature importantces generated from Random Forest. It is interesting that the dummy variable of Title Mr. is the most important feature, while Title Mrs. and Title Miss. are among the least influential features. The Age, Fare, Pclass and Sex variables also rank high in terms of importances, which is expected.\n",
    "## Blend Models\n",
    "We have tried our hands at two models so far and they produced the exact same accuracy. So do both of the models make the same prediction on every test passengers? If not, we could somehow blend these two models together for a better result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 19, 28, 32, 33, 34, 36, 37, 39, 41, 55, 63, 72, 86, 87, 88, 90, 94, 127, 132, 138, 144, 148, 158, 159, 169, 192, 199, 206, 249, 252, 268, 280, 291, 309, 313, 323, 344, 347, 367, 379, 382, 389, 390, 403, 409, 412, 417]\n",
      "Proportion of the predictions that the two models disagree on is  0.101871101871\n"
     ]
    }
   ],
   "source": [
    "# Generating a list of test passenger indexes that have different predictions from the two models\n",
    "different = list()\n",
    "for i in range(len(RFprediction)):\n",
    "    if RFprediction[i] != LRprediction[i]:\n",
    "        different.append(i)\n",
    "print different\n",
    "print \"Proportion of the predictions that the two models disagree on is \" , len(different)/float(481)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does turn out that the two models didn't make the same prediction on every passengers, as the output shows that the models diagree on about 10% of prediction. This is quite desirable since we are very confident on the rest 90% of the predictions. Now we just needed to find a way to blend the two models together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33960866  0.66039134]\n",
      " [ 0.29814563  0.70185437]\n",
      " [ 0.6590034   0.3409966 ]\n",
      " [ 0.53082693  0.46917307]]\n"
     ]
    }
   ],
   "source": [
    "LRProba = bestLRclf.predict_proba(test_data)\n",
    "print LRProba[different[1:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a ensemble method like Random Forest, the interpretbility is very low. However, the Logistic Regression method is actually very intrepretible, as we can compute the probabiliities of the binary responses for each predictions. Here we can see that for the 2nd prediction that the models differed on, the probabilities for 0 and 1 are 0.298 and 0.702, which means that the logistic regression was quite confident that this passengers was gonna survive, whereas for the 5th prediction that the models differed on, the probabilities for 0 and 1 are 0.530 and 0.469, the logistic regression was a lot less confident. Using the probabilities, we could derive an simple method to predict when the two models disagree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "CombinePrediction = deepcopy(RFprediction)\n",
    "for i in range(len(different)):\n",
    "    # If the probabilties of survival is greater than 0.7, predict survived\n",
    "    if LRProba[different[i]][0] > 0.7:\n",
    "        CombinePrediction[different[i]] = 0\n",
    "    # If the probabilties of survival is less than 0.3, predict perished   \n",
    "    elif LRProba[different[i]][0] < 0.3:\n",
    "        CombinePrediction[different[i]] = 1\n",
    "    else:\n",
    "        continue\n",
    "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"],\"Survived\": CombinePrediction})\n",
    "submission.to_csv(\"CombineOutput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us **0.79904**, the best we have had so far and top 25% on the public leaderboard. \n",
    "## Areas of Improvement\n",
    "Of course there is still a lot of room for improvement. \n",
    "- Better tunning of parameters on Logistic Regression and Random Forest. Some people could use one single method to achieve 0.81 or above. Maybe include  [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) in the CV process.\n",
    "- Do a few models and combine them using majority vote. Maybe SVM, or Gradient Boosting. \n",
    "- Better imputation on missing values\n",
    "- Make use of familiy lastnames as a predicator.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
